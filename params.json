{
  "name": "Hyperas",
  "tagline": "Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization",
  "body": "# Hyperas [![Build Status](https://travis-ci.org/maxpumperla/hyperas.svg?branch=master)](https://travis-ci.org/maxpumperla/hyperas)\r\nA very simple convenience wrapper around hyperopt for fast prototyping with keras models. Hyperas lets you use the power of hyperopt without having to learn the syntax of it. Instead, just define your keras model as you are used to, but use a simple template notation to define hyper-parameter ranges to tune.\r\n\r\n## Installation\r\n```{python}\r\npip install hyperas\r\n```\r\n\r\n## Quick start\r\nAssume you have an existing keras model like the following.\r\n```{python}\r\nmodel = Sequential()\r\nmodel.add(Dense(512, input_shape=(784,)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(512))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.2)\r\nmodel.add(Dense(10))\r\nmodel.add(Activation('softmax'))\r\n```\r\nTo do hyper-parameter optimization on this model, just wrap the parameters you want to optimize into double curly brackets and choose a distribution over which to run the algorithm. In the above example, let's say we want to optimize for the best dropout probability in both dropout layers. Choosing a uniform distribution over the interval ```[0,1]```, this translates into the following definition.\r\n\r\n```{python}\r\nfrom hyperas.distributions import uniform\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(512, input_shape=(784,)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout({{uniform(0, 1)}}))\r\nmodel.add(Dense(512))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout({{uniform(0, 1)}}))\r\nmodel.add(Dense(10))\r\nmodel.add(Activation('softmax'))\r\n```\r\n\r\nAfter having trained the model, to optimize, we also have to define which evaluation metric of the model is important to us. For example, if we wish to optimize for accuracy, the following example does the trick:\r\n\r\n```{python}\r\nscore = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\r\naccuracy = score[1]\r\nreturn {'loss': -accuracy, 'status': STATUS_OK}\r\n```\r\nThe last step is to actually run the optimization, which is done as follows:\r\n\r\n```{python}\r\nbest_run = optim.minimize(model=model,\r\n                          data=data,\r\n                          algo=tpe.suggest,\r\n                          max_evals=10,\r\n                          trials=Trials())\r\n```\r\nIn this example we use at most 10 evaluation runs and the TPE algorithm from hyperopt for optimization.\r\n\r\n## Complete example\r\n**Note:** It is important to wrap your data and model into functions, including necessary imports, as shown below, and then pass them as parameters to the minimizer. ```data()``` returns the data the ```model()``` needs. Internally, this is a cheap, but necessary trick to avoid loading data on each optimization run.\r\nAn extended version of the above example in one script reads as follows. This example shows many potential use cases of hyperas, including:\r\n- Varying dropout probabilities, sampling from a uniform distribution\r\n- Different layer output sizes\r\n- Different optimization algorithms to use\r\n- Varying choices of activation functions\r\n- Conditionally adding layers depending on a choice\r\n- Swapping whole sets of layers\r\n\r\n\r\n```{python}\r\nfrom __future__ import print_function\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform, conditional\r\n\r\ndef data():\r\n    '''\r\n    Data providing function:\r\n\r\n    Make sure to have every relevant import statement included here and return data as\r\n    used in model function below. This function is separated from model() so that hyperopt\r\n    won't reload data for each evaluation run.\r\n    '''\r\n    from keras.datasets import mnist\r\n    from keras.utils import np_utils\r\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n    X_train = X_train.reshape(60000, 784)\r\n    X_test = X_test.reshape(10000, 784)\r\n    X_train = X_train.astype('float32')\r\n    X_test = X_test.astype('float32')\r\n    X_train /= 255\r\n    X_test /= 255\r\n    nb_classes = 10\r\n    Y_train = np_utils.to_categorical(y_train, nb_classes)\r\n    Y_test = np_utils.to_categorical(y_test, nb_classes)\r\n    return X_train, Y_train, X_test, Y_test\r\n\r\n\r\ndef model(X_train, Y_train, X_test, Y_test):\r\n    '''\r\n    Model providing function:\r\n\r\n    Create Keras model with double curly brackets dropped-in as needed.\r\n    Return value has to be a valid python dictionary with two customary keys:\r\n        - loss: Specify a numeric evaluation metric to be minimized\r\n        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n    The last one is optional, though recommended, namely:\r\n        - model: specify the model just created so that we can later use it again.\r\n    '''\r\n    from keras.models import Sequential\r\n    from keras.layers.core import Dense, Dropout, Activation\r\n\r\n    model = Sequential()\r\n    model.add(Dense(512, input_shape=(784,)))\r\n    model.add(Activation('relu'))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense({{choice([256, 512, 1024])}}))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n\r\n    # If we choose 'four', add an additional fourth layer\r\n    if conditional({{choice(['three', 'four'])}}) == 'four':\r\n        model.add(Dense(100))\r\n        # We can also choose between complete sets of layers\r\n        model.add({{choice([Dropout(0.5), Activation('linear')])}})\r\n        model.add(Activation('relu'))\r\n\r\n    model.add(Dense(10))\r\n    model.add(Activation('softmax'))\r\n\r\n    model.compile(loss='categorical_crossentropy', optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\r\n\r\n    model.fit(X_train, Y_train,\r\n              batch_size={{choice([64, 128])}},\r\n              nb_epoch=1,\r\n              show_accuracy=True,\r\n              verbose=2,\r\n              validation_data=(X_test, Y_test))\r\n    score, acc = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\r\n    print('Test accuracy:', acc)\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n\r\nif __name__ == '__main__':\r\n    best_run, best_model = optim.minimize(model=model,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=5,\r\n                                          trials=Trials())\r\n    X_train, Y_train, X_test, Y_test = data()\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(X_test, Y_test))\r\n```\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}